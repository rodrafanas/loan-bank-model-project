{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('input/accepted_2007_to_2018Q4.csv.gz', compression='gzip', low_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## METADATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BuildMetadata(dataframe,target,id): \n",
    "\n",
    "    train = dataframe.rename(columns={target:'target',id:'id'})\n",
    "    # Verifica os tipos de variáveis presentes na tabela de treino\n",
    "    t = []\n",
    "    for i in train.columns:\n",
    "            t.append(train[i].dtype)\n",
    "\n",
    "    n = []\n",
    "    for i in train.columns:\n",
    "            n.append(i)\n",
    "\n",
    "    aux_t = pd.DataFrame(data=t,columns=[\"Tipos\"])\n",
    "    aux_n = pd.DataFrame(data=n,columns=[\"Features\"])\n",
    "    # df_tipovars = pd.concat([aux_n, aux_t], axis=1, join_axes=[aux_n.index])\n",
    "    df_tipovars = pd.concat([aux_n, aux_t.reindex(aux_n.index)], axis=1)\n",
    "\n",
    "\n",
    "    data = []\n",
    "    for f in train.columns:\n",
    "\n",
    "        # Definindo o papel das variáveis:\n",
    "        if f == 'target':\n",
    "            role = 'target'\n",
    "        elif f == 'id':\n",
    "            role = 'id'\n",
    "        else:\n",
    "            role = 'input'\n",
    "\n",
    "        # Definindo o tipo das variáveis: nominal, ordinal, binary ou interval\n",
    "        if f == 'target':\n",
    "            level = 'binary'\n",
    "        if train[f].dtype == 'object' or f == 'id': \n",
    "            level = 'nominal'\n",
    "        elif train[f].dtype in ['float','float64'] :\n",
    "            level = 'interval'\n",
    "        elif train[f].dtype in ['int','int64'] :\n",
    "            level = 'ordinal'\n",
    "\n",
    "        # Todas variáveis são incializadas com keep exceto o id\n",
    "        keep = True\n",
    "        if f == 'id':\n",
    "            keep = False\n",
    "\n",
    "        # Definindo o tipo das variáveis da tabela de entrada\n",
    "        dtype = train[f].dtype\n",
    "\n",
    "        # Criando a lista com todo metadados\n",
    "        f_dict = {\n",
    "            'Features': f,\n",
    "            'Role': role,\n",
    "            'Level': level,\n",
    "            'Keep': keep,\n",
    "            'Tipo': dtype\n",
    "        }\n",
    "        data.append(f_dict)\n",
    "\n",
    "    meta = pd.DataFrame(data, columns=['Features', 'Role', 'Level', 'Keep', 'Tipo'])\n",
    "\n",
    "    # Quantidade de domínios distintos para cada cariável do tipo ordinal e nominal\n",
    "    card = []\n",
    "\n",
    "    v = train.columns\n",
    "    for f in v:\n",
    "        dist_values = train[f].value_counts().shape[0]\n",
    "        f_dict = {\n",
    "                'Features': f,\n",
    "                'Cardinality': dist_values\n",
    "            }\n",
    "        card.append(f_dict)\n",
    "\n",
    "    card = pd.DataFrame(card, columns=['Features', 'Cardinality'])\n",
    "\n",
    "    metadados_train = pd.merge(meta, card, on='Features')\n",
    "\n",
    "    return metadados_train "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id = '' \n",
    "target = ''\n",
    "\n",
    "features = [\n",
    "'platform', \n",
    "'graphics_memory_size', \n",
    "'system_memory_size',\n",
    "'adcquision_network', \n",
    "]\n",
    "\n",
    "# \n",
    "select_cols = [id] + features + [target]\n",
    "select_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = BuildMetadata(df[select_cols],target,id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata.to_csv('artifacts/metadata.csv', sep=',', encoding='utf-8',index=False)\n",
    "df[select_cols].to_csv('input/df.csv', sep=',', encoding='utf-8',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "loan_bank",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
